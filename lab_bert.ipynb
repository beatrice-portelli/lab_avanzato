{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "data_path = \"/mnt/HDD/bportelli/lab_avanzato/beatrice.pkl\"\n",
    "with open(data_path, \"rb\") as o:\n",
    "    data = pickle.load(o)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(418153, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Leaf</th>\n",
       "      <th>Category</th>\n",
       "      <th>Block</th>\n",
       "      <th>Chapter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RIF. TRAUMA AL 3° DITO DELLA MANO SN, RISALENT...</td>\n",
       "      <td>9249</td>\n",
       "      <td>924</td>\n",
       "      <td>17.10</td>\n",
       "      <td>CH_17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RIFERISCE TRAUMA EMICOSTATO DX IN SEGUITO A PD...</td>\n",
       "      <td>78002</td>\n",
       "      <td>780</td>\n",
       "      <td>16.1</td>\n",
       "      <td>CH_16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RISCONRO DI HB 7.5 STENOSI PILORICA DI NDD</td>\n",
       "      <td>78900</td>\n",
       "      <td>789</td>\n",
       "      <td>16.1</td>\n",
       "      <td>CH_16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SPALLA SX TRAUMA CONTUSIVO EMICOSTATO SIN</td>\n",
       "      <td>9249</td>\n",
       "      <td>924</td>\n",
       "      <td>17.10</td>\n",
       "      <td>CH_17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DOLORE E BRUCIORE ALLA BOCCA DELLO STOMACO DA ...</td>\n",
       "      <td>07999</td>\n",
       "      <td>079</td>\n",
       "      <td>1.9</td>\n",
       "      <td>CH_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text   Leaf Category  Block  \\\n",
       "0  RIF. TRAUMA AL 3° DITO DELLA MANO SN, RISALENT...   9249      924  17.10   \n",
       "1  RIFERISCE TRAUMA EMICOSTATO DX IN SEGUITO A PD...  78002      780   16.1   \n",
       "2         RISCONRO DI HB 7.5 STENOSI PILORICA DI NDD  78900      789   16.1   \n",
       "3          SPALLA SX TRAUMA CONTUSIVO EMICOSTATO SIN   9249      924  17.10   \n",
       "4  DOLORE E BRUCIORE ALLA BOCCA DELLO STOMACO DA ...  07999      079    1.9   \n",
       "\n",
       "  Chapter  \n",
       "0   CH_17  \n",
       "1   CH_16  \n",
       "2   CH_16  \n",
       "3   CH_17  \n",
       "4    CH_1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of rows:  418153\n",
      "unique values for Text      :    372413\n",
      "unique values for Leaf      :      2390\n",
      "unique values for Category  :       737\n",
      "unique values for Block     :       116\n",
      "unique values for Chapter   :        17\n"
     ]
    }
   ],
   "source": [
    "column_names = data.columns.tolist()\n",
    "print(\"number of rows: \", data.shape[0])\n",
    "for col_name in column_names:\n",
    "    print(\"unique values for {:10}:{:10}\".format(col_name, len(data[col_name].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CH_17    0.273845\n",
       "CH_16    0.202471\n",
       "CH_6     0.101752\n",
       "CH_1     0.093162\n",
       "CH_7     0.077058\n",
       "CH_13    0.054674\n",
       "CH_8     0.051371\n",
       "CH_9     0.043766\n",
       "CH_10    0.026199\n",
       "CH_12    0.024828\n",
       "CH_5     0.021923\n",
       "CH_3     0.012804\n",
       "CH_4     0.007452\n",
       "CH_2     0.004075\n",
       "CH_11    0.003350\n",
       "CH_14    0.001064\n",
       "CH_15    0.000206\n",
       "Name: Chapter, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"Chapter\"].value_counts(normalize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_by_chapter_number(c):\n",
    "    return int(c.split(\"_\")[1])\n",
    "\n",
    "chapters = data[\"Chapter\"].unique().tolist()\n",
    "chapters.sort(key=sort_by_chapter_number)\n",
    "\n",
    "map_chapter_to_label = { c : int(c.split(\"_\")[1]) for c in chapters}\n",
    "map_label_to_chapter = { int(c.split(\"_\")[1]) : c for c in chapters}\n",
    "\n",
    "def chapter_to_label(c):\n",
    "    return map_chapter_to_label[c]\n",
    "\n",
    "def label_to_chapter(l):\n",
    "    return map_label_to_chapter[l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set length 334522\n",
      "test set length     83631\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "all_idx = list(range(0,data.shape[0]))\n",
    "random.shuffle(all_idx)\n",
    "\n",
    "dim_80 = int(data.shape[0]*0.8)\n",
    "dim_20 = data.shape[0]-dim_80\n",
    "\n",
    "training_loc = all_idx[:dim_80]\n",
    "testing_loc = all_idx[dim_80:]\n",
    "\n",
    "print(\"training set length\", len(training_loc))\n",
    "print(\"test set length    \", len(testing_loc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class sample:\n",
    "    def __init__(self, text, label):\n",
    "        self.text = text\n",
    "        self.label = label\n",
    "        self.tokens = None\n",
    "        self.token_ids = None\n",
    "        self.id = None\n",
    "    def __str__(self):\n",
    "        return \"sample(\" + self.text + \", \" + str(self.label) + \")\"\n",
    "    def __repr__(self):\n",
    "        return \"sample(\" + self.text + \", \" + str(self.label) + \")\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_samples = []\n",
    "for idx in testing_loc:\n",
    "    d = data.loc[idx]\n",
    "    s = sample(d[\"Text\"], chapter_to_label(d[\"Chapter\"]))\n",
    "    test_samples.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_transformers import BertTokenizer, BertModel, BertConfig\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "config = BertConfig.from_pretrained(\"bert-base-uncased\", output_hidden_states = True)\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\", config = config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['apple', 'is', 'a', 'fruit'],\n",
       " ['apple', 'is', 'a', 'company'],\n",
       " ['orange', '##s', 'are', 'ta', '##sty', 'fruits'])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1 = \"Apple is a fruit\"\n",
    "text2 = \"Apple is a company\"\n",
    "text3 = \"Oranges are tasty fruits\"\n",
    "\n",
    "tok1 = tokenizer.tokenize(text1)\n",
    "tok2 = tokenizer.tokenize(text2)\n",
    "tok3 = tokenizer.tokenize(text3)\n",
    "\n",
    "(tok1, tok2, tok3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([6207, 2003, 1037, 5909],\n",
       " [6207, 2003, 1037, 2194],\n",
       " [4589, 2015, 2024, 11937, 21756, 10962])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids1 = tokenizer.convert_tokens_to_ids(tok1)\n",
    "ids2 = tokenizer.convert_tokens_to_ids(tok2)\n",
    "ids3 = tokenizer.convert_tokens_to_ids(tok3)\n",
    "\n",
    "(ids1, ids2, ids3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[6207, 2003, 1037, 5909]]),\n",
       " tensor([[6207, 2003, 1037, 2194]]),\n",
       " tensor([[ 4589,  2015,  2024, 11937, 21756, 10962]]))"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "input1 = torch.tensor([ids1])\n",
    "input2 = torch.tensor([ids2])\n",
    "input3 = torch.tensor([ids3])\n",
    "(input1, input2, input3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "out1 = model(input1)\n",
    "out2 = model(input2)\n",
    "out3 = model(input3)\n",
    "\n",
    "layer_number = list(range(13))\n",
    "\n",
    "layers1 = {k:out1[2][-k][0] for k in layer_number}\n",
    "layers2 = {k:out2[2][-k][0] for k in layer_number}\n",
    "layers3 = {k:out3[2][-k][0] for k in layer_number}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "dics = [layers1, layers2, layers3]\n",
    "\n",
    "for d in dics:\n",
    "    d[\"mean3\"] = torch.mean(torch.stack( (d[1], d[2], d[3]) ), dim=0)\n",
    "    d[\"mean5\"] = torch.mean(torch.stack( (d[1], d[2], d[3], d[4], d[5]) ), dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: same, 0: ortho, -1: opposite\n",
      "apple\tapple\t0.79\n",
      "is\tis\t0.82\n",
      "a\ta\t0.82\n",
      "fruit\tcompany\t0.79\n",
      "apple\torange\t0.6\n",
      "apple\torange\t0.58\n"
     ]
    }
   ],
   "source": [
    "print(\"1: same, 0: ortho, -1: opposite\")\n",
    "\n",
    "embedding_depth = \"mean3\"\n",
    "\n",
    "for i in range(len(tok1)):\n",
    "    \n",
    "    v1,v2 = layers1[embedding_depth][i], layers2[embedding_depth][i]\n",
    "    output = F.cosine_similarity(v1.unsqueeze(dim=0), v2.unsqueeze(dim=0))\n",
    "    print(\"{}\\t{}\\t{}\".format(tok1[i], tok2[i], round(float(output[0]),2)))\n",
    "    \n",
    "v1,v2 = layers1[embedding_depth][0], layers3[embedding_depth][0]\n",
    "output = F.cosine_similarity(v1.unsqueeze(dim=0), v2.unsqueeze(dim=0))\n",
    "print(\"{}\\t{}\\t{}\".format(tok1[0], tok3[0], round(float(output[0]),2)))\n",
    "\n",
    "v1,v2 = layers2[embedding_depth][0], layers3[embedding_depth][0]\n",
    "output = F.cosine_similarity(v1.unsqueeze(dim=0), v2.unsqueeze(dim=0))\n",
    "print(\"{}\\t{}\\t{}\".format(tok2[0], tok3[0], round(float(output[0]),2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: same, 0: ortho, -1: opposite\n",
      "apple\tapple\t0.67\n",
      "is\tis\t0.73\n",
      "a\ta\t0.74\n",
      "fruit\tcompany\t0.67\n",
      "apple\torange\t0.4\n",
      "apple\torange\t0.43\n"
     ]
    }
   ],
   "source": [
    "print(\"1: same, 0: ortho, -1: opposite\")\n",
    "\n",
    "embedding_depth = 1\n",
    "\n",
    "for i in range(len(tok1)):\n",
    "    \n",
    "    v1,v2 = layers1[embedding_depth][i], layers2[embedding_depth][i]\n",
    "    output = F.cosine_similarity(v1.unsqueeze(dim=0), v2.unsqueeze(dim=0))\n",
    "    print(\"{}\\t{}\\t{}\".format(tok1[i], tok2[i], round(float(output[0]),2)))\n",
    "    \n",
    "v1,v2 = layers1[embedding_depth][0], layers3[embedding_depth][0]\n",
    "output = F.cosine_similarity(v1.unsqueeze(dim=0), v2.unsqueeze(dim=0))\n",
    "print(\"{}\\t{}\\t{}\".format(tok1[0], tok3[0], round(float(output[0]),2)))\n",
    "\n",
    "v1,v2 = layers2[embedding_depth][0], layers3[embedding_depth][0]\n",
    "output = F.cosine_similarity(v1.unsqueeze(dim=0), v2.unsqueeze(dim=0))\n",
    "print(\"{}\\t{}\\t{}\".format(tok2[0], tok3[0], round(float(output[0]),2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83631/83631 [00:22<00:00, 3665.36it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "274"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "max_tok_length = 0\n",
    "for samp in tqdm(test_samples):\n",
    "    t = tokenizer.tokenize(samp.text)\n",
    "    samp.tokens = t\n",
    "    samp.token_ids = tokenizer.convert_tokens_to_ids(t)\n",
    "    if len(t) > max_tok_length:\n",
    "        max_tok_length = len(t)\n",
    "        \n",
    "max_tok_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sin', '##cope']\n",
      "[10742, 51965]\n"
     ]
    }
   ],
   "source": [
    "print(test_samples[0].tokens)\n",
    "print(test_samples[0].token_ids)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
